\documentclass{lecture}

\institute{Institut für Statistik und Wirtschaftsmathematik}
\title{Vorlesung 11}
\author{Joshua Feld, 406718}
\course{Statistik}
\professor{Cramer}
\semester{Sommersemester 2022}
\program{CES (Bachelor)}

\begin{document}
    \maketitle


    Nun wird in Erweiterung von Beispiel 2 der zehnten Vorlesung allgemein beschrieben, wie man die Hintereinanderausführung ``unabhängiger'' Versuche in einem stochastischen Modell beschreibt.

    Gegeben seien die Modelle \(\parentheses*{\Omega_i, \mathfrak{U}_i, P_i}, 1 \le i \le n\), z.B. Ziehen mit Zurücklegen aus Urnen, Würfelexperimente, usw.
    Ziel ist die Spezifizierung eines Modells für ein Experiment, das aus der unabhängigen Hintereinanderausführung der Teilexperimente besteht (z.B. \(n\)-maliges Ziehen, \(n\)-maliger Würfelwurf, Kombinationen davon, usw.).
    Dann wird ein Wahrscheinlichkeitsraum \(\parentheses*{\Omega, \mathfrak{U}, P}\) eingeführt mit dem Grundraum
    \[
        \Omega = \braces*{\parentheses*{\omega_1, \ldots, \omega_n} : \omega_i \in \Omega_i, 1 \le i \le n} = \bigtimes_{i = 1}^n \Omega_i.
    \]
    Die Mengen \(\Omega_i\) müssen dabei nicht identisch sein.

    \begin{definition}
        Für diskrete Wahrscheinlichkeitsräume \(\parentheses*{\Omega_i, \mathfrak{U}_i, P_i}, 1 \le i \le n\) heißt \(\parentheses*{\Omega, \mathfrak{U}, P}\) mit
        \[
            \Omega = \bigtimes_{i = 1}^n \Omega_i = \braces*{\parentheses*{\omega_1, \ldots, \omega_n} : \omega_i \in \Omega_i, 1 \le i \le n},
        \]
        \(\mathfrak{U}\) Potenzmenge von \(\Omega\) und \(P\) definiert durch die Zähldichte
        \[
            P\parentheses*{\braces*{\omega}} = \prod_{i = 1}^n P_i\parentheses*{\braces*{\omega_i}}, \quad \omega = \parentheses*{\omega_1, \ldots, \omega_n} \in \Omega,
        \]
        \emph{Produkt} der Wahrscheinlichkeitsräume \(\parentheses*{\Omega_i, \mathfrak{U}_i, P_i}, 1 \le i \le n\).
        Der mit
        \[
            \parentheses*{\Omega, \mathfrak{U}, P} = \bigotimes_{i = 1}^n \parentheses*{\Omega_i, \mathfrak{U}_i, P_i} 
        \]
        bezeichnete Wahrscheinlichkeitsraum heißt \emph{Produktraum}.
    \end{definition}

    Damit steht alternativ zur ersten Beschreibung eines ``dreifachen Würfelwurfs'' durch den Grundraum \(\Omega = \braces*{\parentheses*{\omega_1, \omega_2, \omega_3} : \omega_i \in \braces*{1, \ldots, 6}, i \in \braces*{1, 2, 3}}\) und die Zähldichte \(p\parentheses*{\omega_1, \omega_2, \omega_3} = \frac{1}{6^3}\) für jedes \(\parentheses*{\omega_1, \omega_2, \omega_3} \in \Omega\) (Laplace-Raum) nun das ``elegantere'' Modell \(\bigotimes_{i = 1}^3 \parentheses*{\Omega_i, \mathfrak{U}_i, P_i}\) zur Verfügung mit \(\Omega_1 = \Omega_2 = \Omega_3 = \braces*{1, \ldots, 6}\) und \(P_1 = P_2 = P_3\) als Laplace-Verteilungen auf \(\braces*{1, \ldots, 6}\).

    \begin{example}
        Bezeichnet im Beispiel 2 der letzten Vorlesung \(E_k = \braces*{\omega \in \Omega : \sum_{i = 1}^n \omega_i = k}, k \in \braces*{0, \ldots, n}\) das Ereignis, in \(n\) Versuchen genau \(k\)-mal Ergebnis \(1\) zu erhalten, so ist
        \[
            P\parentheses*{E_k} = \binom{n}{k}p^k\parentheses*{1 - p}^{n - k}.
        \]
        Die Ereignisse \(E_0, \ldots, E_n\) sind disjunkt und die durch \(P\parentheses*{E_0}, \ldots, P\parentheses*{E_n}\) definierte Wahrscheinlichkeitsverteilung auf \(\braces*{0, 1, \ldots, n}\) ist die in Definition 1 aus Vorlesung 6 eingeführte Binomialverteilung.
    \end{example}


    \section*{Zufallsvariablen}

    In stochastischen Modellen werden interessierende Merkmale in der Regel mit Zufallsvariablen beschrieben.
    Dies sind Abbildungen von einem zugrundeliegenden Wahrscheinlichkeitsraum in einen neuen Wahrscheinlichkeitsraum, der einerseits eine einfachere Struktur hat und andererseits eine ``gute'' Beschreibung der Zielgröße erlaubt.


    \section*{Zufallsvariablen und Wahrscheinlichkeitsmaße}

    Zufallsvorgänge werden beschrieben durch einen Wahrscheinlichkeitsraum \(\parentheses*{\Omega, \mathfrak{U}, P}\), wobei der Ausgang des Vorgangs ein Element \(\omega\) von \(\Omega\) ist.
    Dabei ist häufg nicht \(\omega \in \Omega\) selbst als Ergebnis von Interesse, sondern ein Funktionswert \(X\parentheses*{\omega}\), wobei \(X\) eine Funktion auf \(\Omega\) ist.

    \begin{example}
        Beschreibt \(\Omega\) den \(n\)-fachen Münzwurf mit \(\omega = \parentheses*{\omega_1, \ldots, \omega_n}, \omega_i \in \braces*{0, 1}, 1 \le i \le n\), so gibt die Funktion \(X\) mit \(X\parentheses*{\omega} = \sum_{i = 1}^n \omega_i\) die Anzahl der Einsen (Anzahl der ``Treffer'') des Vektors \(\omega\) an.
    \end{example}

    Bei der Beschreibung von Telefongesprächen ist oft nicht das Zustandekommen eines Gesprächs und die damit verbundenen Ereignisse (z.B. Uhrzeit, Gesprächspartner usw.) wichtig, sondern nur dessen Dauer.
    Diese wird modelliert als eine sogenannte Realisation einer Zufallsvariable \(Y\), d.h. ein Wert \(Y\parentheses*{\omega}\) für ein \(\omega\) aus einer zugrundeliegenden Grundmenge \(\Omega\), deren Struktur nicht von Interesse oder Bedeutung ist.
    Eine derartige Modellvorstellung liegt auch in naturwissenschaftlichen Experimenten oder für beobachtete ökonomische Größen vor.
    Die gemessenen Ergebnisse, die beobachteten Werte und deren Verteilung sind von Bedeutung, nicht die (exakte) Beschreibung des Zustandekommens.
    In diesem Sinne stellt eine Zufallsvariable eine Fokussierung auf den Untersuchungsgegenstand dar.

    \begin{example}
        \begin{enumerate}
            \item Im \(n\)-fachen unabhängigen Münzwurfexperiment mit Grundmenge \(\Omega = \braces*{0, 1}^n\) ist die Wahrscheinlichkeitsverteilung bestimmt durch die Zähldichte
            \[
                P\parentheses*{\omega} = p^k\parentheses*{1 - p}^{n - k},
            \]
            wobei \(k = \text{Anzahl der Einsen im Vektor }\omega\).
            Dabei ist \(p \in \brackets*{0, 1}\) die Wahrscheinlichkeit für eine Eins bei einem einzelnen Wurf.
            Ist als Zielgröße des Experiments nur die jeweilige Anzahl von Einsen von Interesse (z.B. die Anzahl ``Trefer''), so beschreibt man dies durch die Funktion (Abbildung) \(X\) gegeben durch
            \[
                X: \Omega \to \braces*{0, 1, \ldots, n} = \Omega', \omega \mapsto \sum_{i = 1}^n \omega_i.
            \]
            Für ein \(k \in \braces*{0, \ldots, n}\) ist damit die Wahrscheinlichkeit, dass die Zufallsvariable \(X\) den Wert \(k\) hat, gegeben durch
            \[
                P\parentheses*{X = k} = P\parentheses*{\braces*{\omega \in \Omega : X\parentheses*{\omega} = k}} = \binom{n}{k}p^k\parentheses*{1 - p}^{n - k} = p_k.
            \]
            Dabei ist \(P\parentheses*{X = k}\)  eine vereinfachende Schreibweise für die Wahrscheinlichkeit der Menge aller \(\omega \in \Omega\), die genau \(k\) Einsen enthalten.
            Es gibt \(\binom{n}{k}\) solcher \(\omega\), die jeweils dieselbe Wahrscheinlichkeit \(p^k\parentheses*{1 - p}^{n - k}\) besitzen.
            Wegen \(\sum_{k = 0}^n p_k = 1\) und \(0 \le p_k \le 1\) für alle \(k \in \braces*{0, \ldots, n}\) bilden diese eine diskrete Wahrscheinlichkeitsverteilung auf der Menge \(\Omega'\), die schon bekannte Binomialverteilung.
            \item Im Beispiel B 1.9 bilden die Zahlen
            \[
                q_r = P\parentheses*{\braces*{\omega \in \Omega : \omega_1 + \omega_2 + \omega_3 = r}}, \quad 3 \le r \le 18,
            \]
            wegen \(\sum_{r = 3}^{18}q_r = 1\) eine diskrete Wahrscheinlichkeitsverteilung auf der Menge \(\Omega' = \braces*{3, \ldots, 18}\).
            Die Zufallsvariable \(X\) definiert durch \(X\parentheses*{\parentheses*{\omega_1, \omega_2, \omega_3}} = \omega_1 + \omega_2 + \omega_3\) erzeugt über
            \[
                P\parentheses*{X = k} = P\parentheses*{\braces*{\omega \in \Omega : X\parentheses*{\omega} = k}} = q_k
            \]
            dieses neue Wahrscheinlichkeitsmaß auf \(\Omega'\).
        \end{enumerate}
    \end{example}

    \begin{definition}
        Sei \(\parentheses*{\Omega, \mathfrak{U}, P}\) ein Wahrscheinlichkeitsraum.
        Eine Abbildung \(X: \Omega \to \R^n\) heißt \emph{Zufallsvariable} (falls \(n = 1\)) oder \emph{Zufallsvektor} (falls \(n \ge 2\)).
    \end{definition}

    \begin{lemma}
        Seien \(\parentheses*{\Omega, \mathfrak{U}, P}\) ein Wahrscheinlichkeitsraum, \(X: \Omega \to \R\) und \(\mathcal{B}\) die Borelsche \(\sigma\)-Algebra über \(\R\).
        Dann definiert
        \[
            P^X: \mathcal{B} \to \brackets*{0, 1}\text{ mit }P^X\parentheses*{A} = P\parentheses*{\braces*{\omega \in \Omega : X\parentheses*{\omega} \in A}}, \quad A \in \mathcal{B},
        \]
        eine Wahrscheinlichkeitsverteilung über \(\R\) bzw. über \(X\parentheses*{\Omega} = \braces*{X\parentheses*{\omega} : \omega \in \Omega}\).
        Statt \(P^X\parentheses*{A}\) schreibt man auch \(P\parentheses*{X \in A}\) oder \(P\parentheses*{X = x}\), falls \(A = \braces*{x}, x \in \R\).
        Ist \(\parentheses*{\Omega, \mathfrak{U}, P}\) ein diskreter Wahrscheinlichkeitsraum, so ist \(P^X\) eine diskrete Wahrscheinlichkeitsverteilung über \(X\parentheses*{\Omega}\) bzw. über \(\R\).
    \end{lemma}

    Wird also ein interessierendes Merkmal in einem stochastischen Modell durch eine Zufallsvariable oder einen Zufallsvektor \(X\) beschrieben, so betrachtet man nur noch die Verteilung \(P^X\) ohne Rückgriff auf die explizite Gestalt des zugrundeliegenden Wahrscheinlichkeitsraums \(\parentheses*{\Omega, \mathfrak{U}, P}\).

    \begin{definition}
        Seien \(\parentheses*{\Omega, \mathfrak{U}, P}\) ein Wahrscheinlichkeitsraum und \(X: \Omega \to \R\) eine Zufallsvariable.
        Die Wahrscheinlichkeitsverteilung \(P^X\) definiert durch
        \[
            P^X\parentheses*{A} = P\parentheses*{\braces*{\omega \in \Omega : X\parentheses*{\omega} \in A}}, \quad A \in \mathcal{B},
        \]
        heißt \emph{Verteilung von \(X\) unter \(P\)}.
        Andere Bezeichnungen und Notationen sind: \(X\) hat Verteilung \(P^X\), \(X\) ist verteilt wie \(P^X\), \(X \sim P^X\) oder auch kurz \(X \sim P\).
    \end{definition}

    \begin{remark}
        Für diskrete Wahrscheinlichkeitsverteilungen reicht die Angabe von \(P^X\parentheses*{A}\) für alle einelementigen Mengen des Trägers aus.
        Für Wahrscheinlichkeitsverteilungen mit Riemann-Dichten werden Borelmengen \(A \in \mathcal{B}\) bzw. Einschränkungen von \(A \in \mathcal{B}\) auf ein Intervall betrachtet.
        Es kann gezeigt werden, dass es sogar ausreicht, für \(A\) nur Intervalle des Typs \(\left(-\infty, x\right], x \in \R\) zu betrachten, da die zugehörigen Wahrscheinlichkeiten \(P^X\parentheses*{\left(-\infty, x\right]}\) das Wahrscheinlichkeitsmaß auf \(\mathcal{B}\) eindeutig festlegen.
    \end{remark}

    \begin{example}
        \begin{enumerate}
            \item Die Zufallsvariable \(X\) ist Poisson-verteilt mit Parameter \(\lambda > 0\), falls
            \[
                P^X\parentheses*{k} = P\parentheses*{X = k} * \frac{\lambda^k}{k!}e^{-\lambda}, \quad k \in \N_0.
            \]
            \item \(X\) ist exponentialverteilt mit Parameter \(\lambda > 0\), falls
            \[
                P\parentheses*{X \in \left(-\infty, x\right]} = P\parentheses*{X \le x} = \begin{cases}
                    \int_0^x \lambda e^{-\lambda y}\d y = 1 - e^{-\lambda x}, & \text{falls }x > 0,\\
                    0, & \text{falls }x \le 0.
                \end{cases}
            \]
        \end{enumerate}
    \end{example}

    \begin{definition}
        Seien \(\Omega \ne \emptyset\), \(\parentheses*{\Omega, \mathfrak{U}, P}\) ein Wahrscheinlichkeitsraum und \(A \in \mathfrak{U}\).
        Die Funktion \(\mathcal{I}_A: \Omega \to \R\) definiert durch
        \[
            \mathcal{I}_A\parentheses*{\omega} = \begin{cases}
                1, & \text{falls }\omega \in A,\\
                0, & \text{sonst}
            \end{cases}
        \]
        heißt \emph{Indikatorfunktion} von \(A\).
    \end{definition}

    \begin{remark}
        Für jedes feste \(A \in \mathfrak{U}\) ist \(\mathcal{I}_A\) eine Zufallsvariable, und es gilt \(\mathcal{I}_A \sim \bin\parentheses*{1, p}\) mit \(p = P\parentheses*{A}\), denn
        \begin{align*}
            P\parentheses*{\mathcal{I}_A = 0} &= P\parentheses*{\braces*{\omega \in \Omega : \mathcal{I}_A\parentheses*{\omega} = 0}} = P\parentheses*{A^c} = 1 - p,\\
            P\parentheses*{\mathcal{I}_A = 1} &= P\parentheses*{\braces*{\omega \in \Omega : \mathcal{I}_A\parentheses*{\omega} = 1}} = P\parentheses*{A} = p.
        \end{align*}
        Weiterhin gilt:
        \begin{itemize}
            \item \(\mathcal{I}_{A \cup B} = \max\parentheses*{\mathcal{I}_A, \mathcal{I}_B}\),
            \item \(\mathcal{I}_{A \cup B} = \mathcal{I}_A + \mathcal{I}_B\), falls \(A \cap B = \emptyset\),
            \item \(\mathcal{I}_{A \cap B} = \min\parentheses*{\mathcal{I}_A, \mathcal{I}_B} = \mathcal{I}_A \cdot \mathcal{I}_B\),
            \item \(\mathcal{I}_{A^c} = 1 - \mathcal{I}_A\).
        \end{itemize}
    \end{remark}


    \section*{Stochastische Unabhängigkeit von Zufallsvariablen}

    Eine Zufallsvariable ist eine Abbildung von einem Wahrscheinlichkeitsraum \(\parentheses*{\Omega, \mathfrak{U}, P}\) in einen (anderen) Wahrscheinlichkeitsraum \(\parentheses*{\Omega', \mathfrak{U}', P^X}\).
    In Erweiterung des Begriffs der Unabhängigkeit von Ereignissen wird die Unabhängigkeit von Zufallsvariablen definiert.

    \begin{definition}
        Seien \(I\) eine Indexmenge und \(X_i: \parentheses*{\Omega, \mathfrak{U}, P} \to \parentheses*{\Omega_i, \mathfrak{U}_i, P^{X_i}}, i \in I\) Zufallsvariablen.
        Die Zufallsvariablen \(X_i, i \in I\) heißen \emph{stochastisch unabhängig}, falls
        \[
            P\parentheses*{\bigcap_{i \in J}\braces*{X_i \in A_i}} = \prod_{i \in J}P\parentheses*{X_i \in A_i} \quad \forall J \subseteq I, \absolute*{J} < \infty\text{ und }\forall A_i \in \mathfrak{U}_i, i \in J.
        \]
    \end{definition}

    Die Bedingung in Definition 5 entspricht der stochastischen Unabhängigkeit der Ereignisse \(\parentheses*{\braces*{X_i \in A_i}}_{i \in I}\) für jede Wahr der Ereignisse \(A_i \in \mathfrak{U}_i, i \in I\) und führt damit auf Definition B 6.1.
    Aus dieser eher unhandlichen Definition können vergleichsweise einfache Kriterien für die stochastische unabhängigkeit von Zufallsvariablen abgeleitet werden.

    \begin{lemma}
        Sei \(\parentheses*{\Omega, \mathfrak{U}, P}\) ein diskreter Wahrscheinlichkeitsraum.
        Dann gilt: \(X_i, i \in I\) sind stochastisch unabhängig genau dann, wenn
        \[
            P\parentheses*{X_j = x_j, j \in J} = \prod_{j \in J}P\parentheses*{X_j = x_j} \quad \forall x_j \in X_j\parentheses*{\Omega} \forall j \in J \forall J \subseteq I, \absolute*{J} < \infty.
        \]
    \end{lemma}

    \begin{theorem}
        Sind die Zufallsvariablen \(X_i: \Omega \mapsto \Omega_i, i \in I\) stochastisch unabhängig und sind Abbildungen \(f_i: \Omega_i \mapsto \Omega_i'\) gegeben, dann sind die Zufallsvariablen \(f_i \circ X_i, i \in I\) stochastisch unabhängig.

        Weiterhin gilt für disjunkte Indexmengen \(I_j \subseteq I, j \in J\) und Abbildungen \(g_j: \bigtimes_{i \in I_j}\Omega_i \to \Omega_j', j \in J\):
        \begin{quote}
            \(g_j \circ \parentheses*{X_i, i \in I_j}, j \in J\) sind stochastisch unabhängige Funktionen von Zufallsvariablen mit disjunkten Indexmengen.
        \end{quote}
    \end{theorem}

    \begin{example}
        Sind \(X_1, X_2, X_3\) stochastisch unabhängig, dann sind z.B. auch die Zufallsvariablen \(X_2, X_1 + X_3\) sowie \(X_2^2, \absolute*{X_1 - X_3}\) stochastisch unabhängig.
    \end{example}


    \section*{Summen unabhängiger Zufallsvariablen}

    Summen unabhängiger Zufallsvariablen spielen in vielen Bereichen der Stochastik eine wichtige Rolle und treten etwa beim arithmetischen Mittel von Zufallsvariablen auf.
    Dabei stellt sich die Frage, welche Wahrscheinlichkeitsverteilung eine solche Summe besitzt.
    Zunächst wird der Fall diskret verteilter Zufallsvariablen behandelt.

    \begin{theorem}
        Seien \(X\) und \(Y\) stochastisch unabhängige Zufallsvariablen auf \(\Z = \braces*{\ldots, -2, -1, 0, 1, 2, \ldots}\) mit den Zähldichten \(f\) bzw. \(g\) (d.h. \(P\parentheses*{X = n} = f\parentheses*{n}, P\parentheses*{Y = m} = g\parentheses*{m}, n, m \in \Z\)).
        Dann hat \(X + Y\) die Zähldichte \(h\) gegeben durch:
        \[
            h\parentheses*{k} = \sum_{j \in \Z}f\parentheses*{j} \cdot g\parentheses*{k - j} = \sum_{j \in \Z}f\parentheses*{k - j} \cdot g\parentheses*{j} = P\parentheses*{X + Y = k} = P\parentheses*{\braces*{\omega : X\parentheses*{\omega} + Y\parentheses*{\omega} = k}}, \quad k \in \Z.
        \]
        \(h\) wird Faltung der Dichten \(f\) und \(g\) genannt und mit \(h = f * g\) bezeichnet.
    \end{theorem}

    \begin{proof}
        Es ist \(\sum_{j \in \Z}P\parentheses*{X = j} = \sum_{j \in \Z}P\parentheses*{Y = j} = 1\).
        Mit der Formel von der totalen Wahrscheinlichkeit erhält man
        \begin{align*}
            P\parentheses*{X + Y = k} &= \sum_{j \in Z}P\parentheses*{X + Y = k, Y = j}\\
            &= \sum_{j \in \Z}P\parentheses*{X + j = k, Y = j}\\
            &= \sum_{j \in \Z}P\parentheses*{X = k - j}P\parentheses*{Y = j}\\
            &= \sum_{j \in \Z}f\parentheses*{k - j}g\parentheses*{j}.
        \end{align*}
        Die zweite Darstellung folgt durch Vertauschung der Rollen von \(X\) und \(Y\).
    \end{proof}

    \begin{example}
        \begin{enumerate}
            \item Seien \(X\) und \(Y\) stochastisch unabhängige, \(\bin\parentheses*{1, p}\)-verteilte Zufallsvariablen (d.h. \(P\parentheses*{X = 0} = 1 - p, P\parentheses*{X = 1} = p\)).
            Dann ist
            \begin{align*}
                P\parentheses*{X + Y = k} &= \begin{cases}
                    P\parentheses*{X = 0} \cdot P\parentheses*{Y = 0}, & \text{falls }k = 0,\\
                    P\parentheses*{X = 0} \cdot P\parentheses*{Y = 1} + P\parentheses*{X = 1} \cdot P\parentheses*{Y = 0}, & \text{falls }k = 1,\\
                    P\parentheses*{X = 1} \cdot P\parentheses*{Y = 1}, & \text{falls }k = 2
                \end{cases}\\
                &= \begin{cases}
                    \parentheses*{1 - p}^2, & \text{falls }k = 0,\\
                    2p\parentheses*{1 - p}, & \text{falls }k = 1,\\
                    p^2, & \text{falls }k = 2
                \end{cases}\\
                &= \binom{2}{k}p^k \parentheses*{1 - p}^{2 - k}, \quad k \in \braces*{0, 1, 2},
            \end{align*}
            d.h. \(X + Y \sim \bin\parentheses*{2, p}\).
            Mit vollständiger Induktion folgt die Aussage:
            \begin{quote}
                Seien \(X_1, \ldots, X_n\) stochastisch unabhängige, \(\bin\parentheses*{1, p}\)-verteilte Zufallsvariablen.
                Dann besitzt \(\sum_{i = 1}^n X_i\) eine \(\bin\parentheses*{n, p}\)-Verteilung.
            \end{quote}
            \item Seien \(X\) und \(Y\) stochastisch unabhängige Zufallsvariablen mit \(X \sim \po\parentheses*{\lambda}, Y \sim \po\parentheses*{\mu}, \lambda, \mu > 0\).
            Dann gilt für \(k \in \N_0\):
            \begin{align*}
                P\parentheses*{X + Y = k} &= P\parentheses*{X = k - j} \cdot P\parentheses*{Y = j}\\
                &= \sum_{j = 0}^k \frac{\lambda^{k - j}}{\parentheses*{k - j}!}e^{-\lambda} \cdot \frac{\mu^j}{j!}e^{-\mu}\\
                &= \frac{e^{-\parentheses*{\lambda + \mu}}}{k!}\sum_{j = 0}^k \binom{k}{j}\lambda^{k - j}\mu^j\\
                &= \frac{e^{-\parentheses*{\lambda + \mu}}}{k!}\parentheses*{\lambda + \mu}^k,
            \end{align*}
            d.h. \(X + Y \sim \po \parentheses*{\lambda + \mu}\).
            Die Summe von \(X\) und \(Y\) ist also wiederum Poisson-verteilt.
        \end{enumerate}
    \end{example}
\end{document}
